% 生態系サービス
@BOOK{millennium-ecosystem2005,
  author = {Assesment, Millennium and Van Jaarsveld, Albert},
  year = {2005},
  month = {01},
  pages = {86},
  title = {Ecosystems and Human Well-Being: Biodiversity Synthesis}
}

% 生物多様性国家戦略
@TECHREPORT{biodiversity2023,
  title        = {生物多様性国家戦略2023-2030〜ネイチャーポジディブ実現に向けたロードマップ〜},
  author       = {環境省},
  year         = {2023},
  month        = {3},
  address      = {東京},
  institution  = {環境省 自然環境局},
  note         = {\url{https://www.biodic.go.jp/biodiversity/about/initiatives6/files/1_2023-2030text.pdf}（2024年12月7日確認）},
  language     = {japanese}
}

@ARTICLE{newbold2015,
  author         = {Newbold, Tim and Hudson, Lawrence and Hill, Samantha and Contu, Sara and Lysenko, Igor and Senior, Rebecca and Börger, Luca and Bennett, Dominic and Choimes, Argyrios and Collen, Ben and Day, Julie and De Palma, Adriana and Diaz, Sandra and Echeverria-Londono, Susy and Edgar, Melanie and Feldman, Anat and Garon, Morgan and Harrison, Michelle and Alhusseini, Tamera and Purvis, Andy},
  year           = {2015},
  month          = {04},
  pages          = {45-50},
  title          = {Global effects of land use on local terrestrial biodiversity},
  volume         = {520},
  journal        = {Nature},
  doi            = {10.1038/nature14324}
}

@article{isbell2017,
  author = {Isbell, Forest and Gonzalez, Andrew and Loreau, Michel and Cowles, Jane and Diaz, Sandra and Hector, Andy and Wardle, David and O’Connor, Mary and Duffy, J. and Turnbull, Lindsay and Thompson, Patrick and Larigauderie, Anne},
  year = {2017},
  month = {06},
  pages = {65-72},
  title = {Linking the influence and dependence of people on biodiversity across scales},
  volume = {546},
  journal = {Nature},
  doi = {10.1038/nature22899}
}

% 生態系サービス
@ARTICLE{cardinale2011,
author = {Cardinale, Bradley and Matulich, Kristin and Hooper, David and Byrnes, Jarrett and Duffy, J. and Gamfeldt, Lars and Balvanera, Patricia and O'Connor, Mary and Gonzalez, Andrew},
year = {2011},
month = {03},
pages = {572-92},
title = {The functional role of producer diversity in ecosystems},
volume = {98},
journal = {American journal of botany},
doi = {10.3732/ajb.1000364}
}

% カメラトラップ
@ARTICLE{newey2015,
  author = {Newey, Scott and Davidson G, Paul and Nazir, Sajid and Fairhurst, Gorry and Verdicchio, Fabio and Irvine, Robert and van der Wal, Rene},
  year = {2015},
  month = {11},
  pages = {624-635},
  title = {Limitations of recreational camera traps for wildlife management and conservation research: A practitioner’s perspective},
  volume = {44},
  journal = {Ambio},
  doi = {10.1007/s13280-015-0713-1}
}

% カメラトラップ
@ARTICLE{jia2022,
  author = {Jia, Liang and Tian, Ye and Zhang, Junguo},
  year = {2022},
  month = {02},
  pages = {437},
  title = {Domain-Aware Neural Architecture Search for Classifying Animals in Camera Trap Images},
  volume = {12},
  journal = {Animals},
  doi = {10.3390/ani12040437}
}

% カメラトラップ
@ARTICLE{carl2020,
  author = {Carl, Christin and Schönfeld, Fiona and Profft, Ingolf and Klamm, Alisa and Landgraf, Dirk},
  title = {Automated detection of {European} wild mammal species in camera trap images with an existing and pre-trained computer vision model},
  journal = {European Journal of Wildlife Research},
  volume = {66},
  year = {2020},
  number = {62},
  pages = {},
  doi = {10.1007/s10344-020-01404-y}
}

% 動物分類
@ARTICLE{tan2022,
  author = {Tan, Mengyu and Chao, Wentao and Cheng, Jo-Ku and Zhou, Mo and Ma, Yiwen and Jiang, Xinyi and Ge, Jianping and Yu, Lian and Feng, Limin},
  title = {Animal Detection and Classification from Camera Trap Images Using Different Mainstream Object Detection Architectures},
  journal = {Animals},
  volume = {12},
  year = {2022},
  number = {15},
  article-number = {1976},
  PubMedID = {35953964},
  issn = {2076-2615},
  abstract = {Camera traps are widely used in wildlife surveys and biodiversity monitoring. Depending on its triggering mechanism, a large number of images or videos are sometimes accumulated. Some literature has proposed the application of deep learning techniques to automatically identify wildlife in camera trap imagery, which can significantly reduce manual work and speed up analysis processes. However, there are few studies validating and comparing the applicability of different models for object detection in real field monitoring scenarios. In this study, we firstly constructed a wildlife image dataset of the Northeast Tiger and Leopard National Park (NTLNP dataset). Furthermore, we evaluated the recognition performance of three currently mainstream object detection architectures and compared the performance of training models on day and night data separately versus together. In this experiment, we selected YOLOv5 series models (anchor-based one-stage), Cascade R-CNN under feature extractor HRNet32 (anchor-based two-stage), and FCOS under feature extractors ResNet50 and ResNet101 (anchor-free one-stage). The experimental results showed that performance of the object detection models of the day-night joint training is satisfying. Specifically, the average result of our models was 0.98 mAP (mean average precision) in the animal image detection and 88% accuracy in the animal video classification. One-stage YOLOv5m achieved the best recognition accuracy. With the help of AI technology, ecologists can extract information from masses of imagery potentially quickly and efficiently, saving much time.},
  doi = {10.3390/ani12151976},
  url = {https://www.mdpi.com/2076-2615/12/15/1976}
}

% 動物分類
@ARTICLE{schneider2020,
  author = {Schneider, Stefan and Greenberg, Saul and Taylor, Graham and Kremer, Stefan},
  title = {Three critical factors affecting automated image species recognition performance for camera traps},
  journal = {Ecology and Evolution},
  volume = {10},
  number = {7},
  year = {2020},
  pages = {3503--3517},
  doi = {10.1002/ece3.6147}
}

% 動物分類
@ARTICLE{manna2023,
  title = {Bird Image Classification using Convolutional Neural Network Transfer Learning Architectures},
  journal = {International Journal of Advanced Computer Science and Applications},
  doi = {10.14569/IJACSA.2023.0140397},
  url = {http://dx.doi.org/10.14569/IJACSA.2023.0140397},
  year = {2023},
  publisher = {The Science and Information Organization},
  volume = {14},
  number = {3},
  author = {Asmita Manna and Nilam Upasani and Shubham Jadhav and Ruturaj Mane and Rutuja Chaudhari and Vishal Chatre}
}

@ARTICLE{mohanty2022, 
  place={Houston, USA}, 
  title={Fish Species Image Classification Using Convolutional Neural Networks}, 
  volume={11}, 
  url={https://www.jsr.org/hs/index.php/path/article/view/3058}, 
  DOI={10.47611/jsrhs.v11i3.3058}, 
  abstractNote={&lt;p&gt;This paper demonstrates the classification of various fish species using different machine learning methods. By incorporating machine learning algorithms, modeling, and training, the project classifies fish species using neural networks with the help of multiple features like length, width, and more. Ultimately, this project attempts to analyze the differences between determining fish species with PyTorch and TensorFlow. Convolutional Neural Networks (CNN) is a powerful algorithm used in image classification problems. Python has various libraries which can be used to build a model for the same purpose; the ultimate goal of this study is to see whether using different libraries will affect the accuracy. I would like to see whether new and more advanced methods can be used to classify large schools of fish rather than only in labs. I developed separate Python codes using PyTorch and TensorFlow individually. Using each code, I obtained results and, in the end, performed a comparative study between both to come to my conclusion. My main findings were that PyTorch gave a more accurate prediction than TensorFlow. I believe this was the case because the PyTorch code incorporated neural networks with more layers, so it increased the training and validation accuracy. From here, it is evident that while neither method necessarily possesses setbacks, PyTorch has a significant edge in accuracy (99.75% to 87.22%). Therefore, when scientists apply classification with CNN, PyTorch may be more optimal for producing better results.&lt;/p&gt;}, 
  number={3}, 
  journal={Journal of Student Research}, 
  author={Mohanty, Anishka and Goldsztein, Guillermo and Pellegrin, Raphaël}, 
  year={2022}, 
  month={Aug.}
}

% 動物分類
@INPROCEEDINGS{agarwal2023,
  author={Agarwal, Nikita and Kalita, Tina and Dubey, Ashwani Kumar},
  booktitle={International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES)}, 
  title={Classification of Insect Pest Species using CNN based Models}, 
  year={2023},
  volume={},
  number={},
  pages={862-866},
  keywords={Training;Deep learning;Planets;Insects;Sociology;Real-time systems;Mobile applications;Deep Learning;insect identification;insect pest;image classification;IP102},
  doi={10.1109/CISES58720.2023.10183545}
}

% 動物分類
@INPROCEEDINGS{neeli2023,
  author={Neeli, Subash and Guruguri, Chandra Sekhar Reddy and Kammara, Adithya Ram Achari and Annepu, Visalakshi and Bagadi, Kalapraveen and Chirra, Venkata Rami Reddy},
  booktitle={International Conference on Next Generation Electronics (NEleX)}, 
  title={Bird Species Detection Using CNN and EfficientNet-B0}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Biological system modeling;Computational modeling;Transfer learning;Computer architecture;Birds;Convolutional neural networks;Monitoring;CNN;EfficientNet-B0;Hierarchical traits Categorization;Bird Species},
  doi={10.1109/NEleX59773.2023.10420966}
}

% カメラトラップ
@INPROCEEDINGS{zhu2017,
  author={Zhu, Chunbiao and Li, Thomas H. and Li, Ge},
  booktitle={IEEE International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Towards Automatic Wild Animal Detection in Low Quality Camera-Trap Images Using Two-Channeled Perceiving Residual Pyramid Networks}, 
  year={2017},
  volume={},
  number={},
  pages={2860-2864},
  keywords={Wildlife;Feature extraction;Cameras;Image segmentation;Computer vision;Training},
  doi={10.1109/ICCVW.2017.337}
}

% カメラトラップ
@INPROCEEDINGS{schneider2018,
  author={Schneider, Stefan and Taylor, Graham W. and Kremer, Stefan},
  booktitle={15th Conference on Computer and Robot Vision (CRV)}, 
  title={Deep Learning Object Detection Methods for Ecological Camera Trap Data}, 
  year={2018},
  volume={},
  number={},
  pages={321-328},
  keywords={Cameras;Object detection;Animals;Computer vision;Task analysis;Sociology;Camera Trap;Object Detector;Transfer Learning;Ecology;Faster R CNN;YOLO;Snapshot Serengeti;Deep Learning;Convolutional Neural Network},
  doi={10.1109/CRV.2018.00052}
}

% 赤外線画像
@INPROCEEDINGS{kishimoto2023,
  author = {Kishi, Koki and Kishimoto, Masako and Situju, Sulfayanti and Takimoto, Hironori and Kanagawa, Akihiro},
  booktitle = {10th IIAE International Conference on Intelligent Systems and Image Processing (ICISIP)},
  title = {Few-Shot Learning for {CNN}-based Animal Classification in Camera Traps using an Infrared Camera},
  year = {2023},
  pages = {11-17},
  doi = {10.12792/icisip2023.005}
}

% OSR
@INPROCEEDINGS{sun2020,
  author={Sun, Xin and Yang, Zhenning and Zhang, Chi and Ling, Keck-Voon and Peng, Guohao},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Conditional Gaussian Distribution Learning for Open Set Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={13477-13486},
  keywords={Feature extraction;Training;Task analysis;Testing;Probabilistic logic;Decoding;Anomaly detection},
  doi={10.1109/CVPR42600.2020.01349}
}

% OSR
@INPROCEEDINGS{sagar2022,
  title={Open-Set Recognition: A Good Closed-Set Classifier is All You Need},
  author={Sagar Vaze and Kai Han and Andrea Vedaldi and Andrew Zisserman},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
url={https://openreview.net/forum?id=5hLP5JY9S2d}
}

% FSOSR
@INPROCEEDINGS{peeler,
  author={Liu, Bo and Kang, Hao and Li, Haoxiang and Hua, Gang and Vasconcelos, Nuno},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Few-Shot Open-Set Recognition Using Meta-Learning}, 
  year={2020},
  volume={},
  number={},
  pages={8795-8804},
  keywords={Training;Measurement;Task analysis;Robustness;Entropy;Image recognition;Face recognition},
  doi={10.1109/CVPR42600.2020.00882}}

% FSOSR
@INPROCEEDINGS{snatcher,
  author={Jeong, Minki and Choi, Seokeon and Kim, Changick},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Few-shot Open-set Recognition by Transformation Consistency}, 
  year={2021},
  volume={},
  number={},
  pages={12561-12570},
  keywords={Learning systems;Computer vision;Adaptation models;Prototypes;Estimation;Detectors;Pattern recognition},
  doi={10.1109/CVPR46437.2021.01238}}

% ViTとCNNが重視する特徴
@ARTICLE{feature,
    title={Are Convolutional Neural Networks or Transformers more like human vision?},
    author={Shikhar Tuli and Ishita Dasgupta and Erin Grant and Thomas L. Griffiths},
    year={2021},
    journal={arXiv preprint arXiv:2105.07197},
    eprint={2105.07197},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

% ViT
@INPROCEEDINGS{vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021},
  url={https://openreview.net/forum?id=YicbFdNTTy}
}

% FDSL
@ARTICLE{fdsl,
  author = {Kataoka, Hirokatsu and Okayasu, Kazushige and Matsumoto, Asato and Yamagata, Eisuke and Yamada, Ryosuke and Inoue, Nakamasa and Nakamura, Akio and Satoh, Yutaka},
  title = {Pre-training without Natural Images},
  journal = {International Journal of Computer Vision (IJCV)},
  year = {2022}
}

% k-means loss
@INPROCEEDINGS{k-means,
  author={Tsai, Chin-Chia and Wu, Tsung-Hsuan and Lai, Shang-Hong},
  booktitle={IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Multi-Scale Patch-Based Representation Learning for Image Anomaly Detection and Segmentation}, 
  year={2022},
  volume={},
  number={},
  pages={3992--4000},
  keywords={Representation learning;Training;Image segmentation;Computer vision;Image representation;Benchmark testing;Feature extraction;Industrial Inspection Transfer;Few-shot;Semi- and Un- supervised Learning},
  doi={10.1109/WACV51458.2022.00312}
}

% ResNet
@INPROCEEDINGS{resnet,
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Deep Residual Learning for Image Recognition}, 
  year={2016},
  volume={},
  number={},
  pages={770-778},
  keywords={Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
  doi={10.1109/CVPR.2016.90}
}

% ProtNet
@ARTICLE{protonet,
  author    = {Jake Snell and
               Kevin Swersky and
               Richard S. Zemel},
  title     = {Prototypical Networks for Few-shot Learning},
  journal   = {CoRR},
  volume    = {abs/1703.05175},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.05175},
  archivePrefix = {arXiv},
  eprint    = {1703.05175},
  timestamp = {Wed, 07 Jun 2017 14:41:38 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/corr/SnellSZ17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

% CCT
@INPROCEEDINGS{cct,
  author = {Beery, Sara and Van Horn, Grant and Perona, Pietro},
  title = {Recognition in Terra Incognita},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2018}
}